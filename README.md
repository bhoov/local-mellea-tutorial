# Local Mellea Tutorial -- IBM-GT TechXchange

Run this tutorial locally! You will need a device with at least 16GB RAM (an M-series apple silicon mac works well). The tutorial notebook will be faster with a GPU and fast internet connection.

1. Download and install ollama (https://ollama.com/download)
2. [Download `uv`](https://docs.astral.sh/uv/getting-started/installation/). (Run `curl -LsSf https://astral.sh/uv/install.sh | sh` on linux/unix systems)
3. Run `uv sync`

Open `Tutorial.ipynb` in your favorite jupyter editor (e.g., [VSCode](https://code.visualstudio.com/download)), selecting the `.venv` python kernel